diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
index 1dd7eb6..98c4875 100644
--- a/Trajectory_Transformer/config/offline.py
+++ b/Trajectory_Transformer/config/offline.py
@@ -17,7 +17,7 @@ args_to_watch = [
 base = {
 
     'train': {
-        'N': 100,
+        'N': 20,
         'discount': 0.99,
         'n_layer': 4,
         'n_head': 4,
diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
index 881688c..335869f 100644
--- a/Trajectory_Transformer/scripts/plan.py
+++ b/Trajectory_Transformer/scripts/plan.py
@@ -3,6 +3,7 @@ import pdb
 from os.path import join
 import gym
 import gym_anytrading
+import numpy as np
 from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
 from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
 import trajectory.utils as utils
@@ -90,7 +91,7 @@ for t in range(T):
     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
 
     ## execute action in environment
-    next_observation, reward, terminal, _ = env.step(action)
+    next_observation, reward, terminal, _ = env.step(np.argmax(action))
 
     ## update return
     total_reward += reward
diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
index ddcda7a..913d790 100644
--- a/Trajectory_Transformer/scripts/train.py
+++ b/Trajectory_Transformer/scripts/train.py
@@ -2,11 +2,17 @@ import os
 import numpy as np
 import torch
 import pdb
+import sys
+
+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
+sys.path.insert(0, parent_dir)
 
 import trajectory.utils as utils
 import trajectory.datasets as datasets
 from trajectory.models.transformers import GPT
 
+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
 
 class Parser(utils.Parser):
     dataset: str = 'forex-v0'
@@ -31,7 +37,7 @@ dataset_config = utils.Config(
     savepath=(args.savepath, 'data_config.pkl'),
     env=args.dataset,
     N=args.N,
-    penalty=args.termination_penalty,
+    penalty=None,
     sequence_length=sequence_length,
     step=args.step,
     discount=args.discount,
diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
deleted file mode 100644
index fa97c75..0000000
Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
index 71bfb7e..bbd08e4 100644
--- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
 action_dim = env.action_space.n
 
 episode = 10
-
+T = 0
 episode_data = {}
 for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
     episode_data[k] = []
@@ -25,13 +25,12 @@ for _ in range(episode):
         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
         episode_data['actions'].append(action)
-        episode_data['rewards'].append(np.array(reward).astype('float32'))
+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
         episode_data['terminals'].append(done)
         if done:
             break
 
 for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
     episode_data[k] = np.stack(episode_data[k])
-
-with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
     pickle.dump(episode_data, f)
\ No newline at end of file
diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
index 69ee58d..d1062c5 100644
--- a/Trajectory_Transformer/trajectory/datasets/__init__.py
+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .d4rl import load_environment
+#from .d4rl import load_environment
 from .sequence import *
 from .preprocessing import get_preprocess_fn
diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
index c23b4f3..4525194 100644
--- a/Trajectory_Transformer/trajectory/datasets/sequence.py
+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
         self.device = device
         
         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
-        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
             dataset = pickle.load(f)
         print('âœ“')
 
@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
         terminals = dataset['terminals']
         realterminals = [False]*len(dataset['terminals'])
 
-        #observations = np.reshape(observations, (100, 7000))
         self.observations_raw = observations
         self.actions_raw = actions
         self.next_observations_raw = next_observations
diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
index 7c596c3..7529384 100644
--- a/Trajectory_Transformer/trajectory/utils/__init__.py
+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
@@ -2,7 +2,7 @@ from .setup import Parser, watch
 from .arrays import *
 from .serialization import *
 from .progress import Progress, Silent
-from .rendering import make_renderer
+#from .rendering import make_renderer
 # from .video import *
 from .config import Config
 from .training import Trainer
diff --git a/requirements.txt b/requirements.txt
index ece16ed..a579177 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,14 +1,16 @@
 numpy
 gym
 numpy
-torch
+pytorch==1.12.1
+torchvision==0.13.1 
+torchaudio==0.12.1
 transformers==4.5.1
 wandb==0.9.1
 tensorboard
 pyprind
 tensorflow
 gin-config
-gym
+gym==0.21.0
 tqdm
 blosc
 git+https://github.com/google/dopamine.git